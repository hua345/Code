server.port=9002
spring.application.name=kafka
#kafka默认消费者配置
spring.kafka.consumer.bootstrapServers=192.168.137.128:9092,192.168.137.128:9093,192.168.137.128:9094
spring.kafka.consumer.enable-auto-commit=false
# earliest：当各分区有已提交的offset时，从提交的offset开始消费，无提交的offset时，从头开始消费
# latest：(默认)当各分区有已提交的offset时，从提交的offset开始消费，无提交的offset时，消费新产生的该分区下的数据
spring.kafka.consumer.auto-offset-reset=latest
#kafka默认生产者配置
spring.kafka.producer.bootstrap-servers=192.168.137.128:9092,192.168.137.128:9093,192.168.137.128:9094
#procedure要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下：
#0:不需要leader和replica副本确认。在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。
#1:leader写入partition成功后就返回,不需要等待其他partition对应的replica副本写入。在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。
#all或者-1: leader和replica副本都写入partition成功后返回。这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，这是最强有力的保证。
#可以设置的值为：all, -1, 0, 1
spring.kafka.producer.acks=all
spring.kafka.client-id=fangKafkaClientId
spring.kafka.producer.batch-size=5